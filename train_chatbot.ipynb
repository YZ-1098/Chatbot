{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531b4e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pickle\n",
    "import os\n",
    "from typing import List, Tuple, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16a0239",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2a457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_conversation_csv(csv_path: str) -> Tuple[List[str], List[str], Optional[List[str]]]:\n",
    "    questions: List[str] = []\n",
    "    answers: List[str] = []\n",
    "    categories: List[str] = []\n",
    "    with open(csv_path, newline='', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        # Expecting columns: question, answer, [optional] category\n",
    "        for row in reader:\n",
    "            q = (row.get('question') or '').strip()\n",
    "            a = (row.get('answer') or '').strip()\n",
    "            if not q or not a:\n",
    "                continue\n",
    "            questions.append(q)\n",
    "            answers.append(a)\n",
    "            cat = (row.get('category') or '').strip()\n",
    "            categories.append(cat if cat else '')\n",
    "    if not questions:\n",
    "        raise ValueError(\"No question/answer rows found in Conversation.csv\")\n",
    "    # Return categories only if at least one non-empty exists\n",
    "    return questions, answers, (categories if any(categories) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bef4021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_retriever(questions: List[str]):\n",
    "    # Character n-grams are robust to spelling/wording variations\n",
    "    vectorizer = TfidfVectorizer(lowercase=True,\n",
    "                                 analyzer='char_wb',\n",
    "                                 ngram_range=(3, 5),\n",
    "                                 min_df=1)\n",
    "    question_matrix = vectorizer.fit_transform(questions)\n",
    "    return vectorizer, question_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f891a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_artifacts(vectorizer, question_matrix, answers: List[str], questions: List[str], categories: Optional[List[str]], out_dir: str = \".\"):\n",
    "    with open(os.path.join(out_dir, \"tfidf_vectorizer.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(vectorizer, f)\n",
    "    with open(os.path.join(out_dir, \"qa_answers.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(answers, f)\n",
    "    # Pickle sparse matrix (requires scipy in sklearn deps, safe to pickle)\n",
    "    with open(os.path.join(out_dir, \"qa_matrix.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(question_matrix, f)\n",
    "    # Also save questions for display and optional categories for filtering\n",
    "    with open(os.path.join(out_dir, \"qa_questions.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(questions, f)\n",
    "    if categories is not None:\n",
    "        with open(os.path.join(out_dir, \"qa_categories.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(categories, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82280c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    csv_path = \"Conversation.csv\"\n",
    "    if not os.path.exists(csv_path):\n",
    "        # Allow alternate provided filename just in case\n",
    "        alt = \"Conversations.csv\"\n",
    "        if os.path.exists(alt):\n",
    "            csv_path = alt\n",
    "        else:\n",
    "            raise FileNotFoundError(\"Conversation.csv not found in project root\")\n",
    "\n",
    "    questions, answers, categories = read_conversation_csv(csv_path)\n",
    "    vectorizer, question_matrix = train_retriever(questions)\n",
    "    save_artifacts(vectorizer, question_matrix, answers, questions, categories)\n",
    "    extra = \" with categories\" if categories is not None else \"\"\n",
    "    print(f\"Trained retrieval model on {len(questions)} Q/A pairs{extra} and saved artifacts.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
