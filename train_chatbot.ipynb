{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "531b4e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pickle\n",
    "import os\n",
    "from typing import List, Tuple, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e16a0239",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeature_extraction\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpairwise\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d2a457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_conversation_csv(csv_path: str) -> Tuple[List[str], List[str], Optional[List[str]]]:\n",
    "    questions: List[str] = []\n",
    "    answers: List[str] = []\n",
    "    categories: List[str] = []\n",
    "    with open(csv_path, newline='', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        # Expecting columns: question, answer, [optional] category\n",
    "        for row in reader:\n",
    "            q = (row.get('question') or '').strip()\n",
    "            a = (row.get('answer') or '').strip()\n",
    "            if not q or not a:\n",
    "                continue\n",
    "            questions.append(q)\n",
    "            answers.append(a)\n",
    "            cat = (row.get('category') or '').strip()\n",
    "            categories.append(cat if cat else '')\n",
    "    if not questions:\n",
    "        raise ValueError(\"No question/answer rows found in Conversation.csv\")\n",
    "    # Return categories only if at least one non-empty exists\n",
    "    return questions, answers, (categories if any(categories) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bef4021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_retriever(questions: List[str]):\n",
    "    # Character n-grams are robust to spelling/wording variations\n",
    "    vectorizer = TfidfVectorizer(lowercase=True,\n",
    "                                 analyzer='char_wb',\n",
    "                                 ngram_range=(3, 5),\n",
    "                                 min_df=1)\n",
    "    question_matrix = vectorizer.fit_transform(questions)\n",
    "    return vectorizer, question_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20f891a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_artifacts(vectorizer, question_matrix, answers: List[str], questions: List[str], categories: Optional[List[str]], out_dir: str = \".\"):\n",
    "    with open(os.path.join(out_dir, \"tfidf_vectorizer.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(vectorizer, f)\n",
    "    with open(os.path.join(out_dir, \"qa_answers.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(answers, f)\n",
    "    # Pickle sparse matrix (requires scipy in sklearn deps, safe to pickle)\n",
    "    with open(os.path.join(out_dir, \"qa_matrix.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(question_matrix, f)\n",
    "    # Also save questions for display and optional categories for filtering\n",
    "    with open(os.path.join(out_dir, \"qa_questions.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(questions, f)\n",
    "    if categories is not None:\n",
    "        with open(os.path.join(out_dir, \"qa_categories.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(categories, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82280c5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TfidfVectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mConversation.csv not found in project root\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m questions, answers, categories = read_conversation_csv(csv_path)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m vectorizer, question_matrix = \u001b[43mtrain_retriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m save_artifacts(vectorizer, question_matrix, answers, questions, categories)\n\u001b[32m     15\u001b[39m extra = \u001b[33m\"\u001b[39m\u001b[33m with categories\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m categories \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mtrain_retriever\u001b[39m\u001b[34m(questions)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_retriever\u001b[39m(questions: List[\u001b[38;5;28mstr\u001b[39m]):\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# Character n-grams are robust to spelling/wording variations\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     vectorizer = \u001b[43mTfidfVectorizer\u001b[49m(lowercase=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      4\u001b[39m                                  analyzer=\u001b[33m'\u001b[39m\u001b[33mchar_wb\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      5\u001b[39m                                  ngram_range=(\u001b[32m3\u001b[39m, \u001b[32m5\u001b[39m),\n\u001b[32m      6\u001b[39m                                  min_df=\u001b[32m1\u001b[39m)\n\u001b[32m      7\u001b[39m     question_matrix = vectorizer.fit_transform(questions)\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m vectorizer, question_matrix\n",
      "\u001b[31mNameError\u001b[39m: name 'TfidfVectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    csv_path = \"Conversation.csv\"\n",
    "    if not os.path.exists(csv_path):\n",
    "        # Allow alternate provided filename just in case\n",
    "        alt = \"Conversations.csv\"\n",
    "        if os.path.exists(alt):\n",
    "            csv_path = alt\n",
    "        else:\n",
    "            raise FileNotFoundError(\"Conversation.csv not found in project root\")\n",
    "\n",
    "    questions, answers, categories = read_conversation_csv(csv_path)\n",
    "    vectorizer, question_matrix = train_retriever(questions)\n",
    "    save_artifacts(vectorizer, question_matrix, answers, questions, categories)\n",
    "    extra = \" with categories\" if categories is not None else \"\"\n",
    "    print(f\"Trained retrieval model on {len(questions)} Q/A pairs{extra} and saved artifacts.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
