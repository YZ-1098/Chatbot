{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac3819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from typing import List, Tuple, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e110acb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import streamlit as st\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f04a78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@st.cache_resource(show_spinner=False)\n",
    "def load_artifacts():\n",
    "    base_dir = os.path.dirname(__file__)\n",
    "    with open(os.path.join(base_dir, \"tfidf_vectorizer.pkl\"), \"rb\") as f:\n",
    "        vectorizer = pickle.load(f)\n",
    "    with open(os.path.join(base_dir, \"qa_matrix.pkl\"), \"rb\") as f:\n",
    "        qa_matrix = pickle.load(f)\n",
    "    with open(os.path.join(base_dir, \"qa_answers.pkl\"), \"rb\") as f:\n",
    "        answers = pickle.load(f)\n",
    "    # Optional artifacts\n",
    "    questions: Optional[List[str]] = None\n",
    "    categories: Optional[List[str]] = None\n",
    "    q_path = os.path.join(base_dir, \"qa_questions.pkl\")\n",
    "    c_path = os.path.join(base_dir, \"qa_categories.pkl\")\n",
    "    if os.path.exists(q_path):\n",
    "        with open(q_path, \"rb\") as f:\n",
    "            questions = pickle.load(f)\n",
    "    if os.path.exists(c_path):\n",
    "        with open(c_path, \"rb\") as f:\n",
    "            categories = pickle.load(f)\n",
    "    return vectorizer, qa_matrix, answers, questions, categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9539546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_top_k(user_text: str, vectorizer, qa_matrix, answers: List[str], top_k: int) -> List[Tuple[str, float, int]]:\n",
    "    user_vec = vectorizer.transform([user_text])\n",
    "    sims = cosine_similarity(user_vec, qa_matrix).flatten()\n",
    "    top_idx = np.argsort(sims)[::-1][:top_k]\n",
    "    results: List[Tuple[str, float, int]] = []\n",
    "    for idx in top_idx:\n",
    "        results.append((answers[idx], float(sims[idx]), int(idx)))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201935b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.set_page_config(page_title=\"CSV Chatbot\", page_icon=\"ðŸ’¬\", layout=\"centered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda58efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.title(\"ðŸ’¬ FAQ Chatbot\")\n",
    "st.caption(\"TFâ€‘IDF retrieval over your FAQ CSV (question, answer, optional category)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68ed531",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer, qa_matrix, answers, questions, categories = load_artifacts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976db2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with st.sidebar:\n",
    "    st.header(\"Settings\")\n",
    "    threshold = st.slider(\"Match threshold\", 0.0, 1.0, 0.35, 0.01)\n",
    "    top_k = st.slider(\"Show topâ€‘k matches\", 1, 5, 3, 1)\n",
    "    show_candidates = st.checkbox(\"Show candidates\", value=False)\n",
    "    st.markdown(\"---\")\n",
    "    st.subheader(\"Upload new FAQ CSV\")\n",
    "    uploaded = st.file_uploader(\"CSV with columns: question, answer, [category]\", type=[\"csv\"], accept_multiple_files=False)\n",
    "    if uploaded is not None:\n",
    "        # Session-only retrain using uploaded CSV\n",
    "        import csv as _csv\n",
    "        from io import StringIO\n",
    "        # Read rows\n",
    "        decoded = uploaded.getvalue().decode(\"utf-8\", errors=\"ignore\")\n",
    "        reader = _csv.DictReader(StringIO(decoded))\n",
    "        qs: List[str] = []\n",
    "        ans: List[str] = []\n",
    "        cats: List[str] = []\n",
    "        for row in reader:\n",
    "            q = (row.get('question') or '').strip()\n",
    "            a = (row.get('answer') or '').strip()\n",
    "            if not q or not a:\n",
    "                continue\n",
    "            qs.append(q)\n",
    "            ans.append(a)\n",
    "            c = (row.get('category') or '').strip()\n",
    "            cats.append(c if c else '')\n",
    "        if qs:\n",
    "            from sklearn.feature_extraction.text import TfidfVectorizer as _V\n",
    "            _vec = _V(lowercase=True, analyzer='char_wb', ngram_range=(3, 5), min_df=1)\n",
    "            _mat = _vec.fit_transform(qs)\n",
    "            # Overwrite session artifacts only\n",
    "            vectorizer = _vec\n",
    "            qa_matrix = _mat\n",
    "            answers = ans\n",
    "            questions = qs\n",
    "            categories = cats if any(cats) else None\n",
    "            st.success(f\"Loaded {len(qs)} Q/A pairs from uploaded CSV for this session.\")\n",
    "    # Category filter if available\n",
    "    active_category = None\n",
    "    if categories:\n",
    "        unique_cats = sorted({c for c in categories if c})\n",
    "        if unique_cats:\n",
    "            selected = st.selectbox(\"Filter by category\", [\"(All)\"] + unique_cats, index=0)\n",
    "            active_category = None if selected == \"(All)\" else selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae48419a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"history\" not in st.session_state:\n",
    "    st.session_state.history = []  # list of (role, text)\n",
    "if \"ratings\" not in st.session_state:\n",
    "    st.session_state.ratings = []  # list of dicts {turn, prompt, reply, score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7146f040",
   "metadata": {},
   "outputs": [],
   "source": [
    "for role, text in st.session_state.history:\n",
    "    with st.chat_message(role):\n",
    "        st.markdown(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a58d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = st.chat_input(\"Type your messageâ€¦\")\n",
    "if prompt:\n",
    "    st.session_state.history.append((\"user\", prompt))\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(prompt)\n",
    "\n",
    "    # If filtering by category, zero out similarities for items not in the category\n",
    "    if active_category and categories:\n",
    "        user_vec = vectorizer.transform([prompt])\n",
    "        sims = cosine_similarity(user_vec, qa_matrix).flatten()\n",
    "        mask = np.array([1.0 if categories[i] == active_category else 0.0 for i in range(len(answers))], dtype=float)\n",
    "        sims = sims * mask\n",
    "        order = np.argsort(sims)[::-1][:top_k]\n",
    "        candidates = [(answers[i], float(sims[i]), int(i)) for i in order]\n",
    "    else:\n",
    "        candidates = retrieve_top_k(prompt, vectorizer, qa_matrix, answers, top_k=top_k)\n",
    "    best_answer, best_score, _ = candidates[0]\n",
    "    if best_score < threshold:\n",
    "        reply = \"Iâ€™m not sure yet. Could you rephrase or ask something else?\"\n",
    "    else:\n",
    "        reply = best_answer\n",
    "\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        st.markdown(reply)\n",
    "        if show_candidates:\n",
    "            with st.expander(\"View candidates\"):\n",
    "                for ans, score, idx in candidates:\n",
    "                    meta = []\n",
    "                    if questions and 0 <= idx < len(questions):\n",
    "                        meta.append(f\"Q: {questions[idx]}\")\n",
    "                    if categories and 0 <= idx < len(categories) and categories[idx]:\n",
    "                        meta.append(f\"Category: {categories[idx]}\")\n",
    "                    st.write(f\"Score: {score:.3f} | idx: {idx}\")\n",
    "                    if meta:\n",
    "                        st.caption(\" | \".join(meta))\n",
    "                    st.text(ans)\n",
    "                    st.markdown(\"---\")\n",
    "\n",
    "    st.session_state.history.append((\"assistant\", reply))\n",
    "\n",
    "    # Usability rating UI per assistant reply\n",
    "    with st.container(border=True):\n",
    "        st.write(\"Rate this response (1=poor, 5=excellent):\")\n",
    "        col1, col2 = st.columns([1, 3])\n",
    "        with col1:\n",
    "            rating = st.slider(\"Rating\", 1, 5, 4, 1, key=f\"rate_{len(st.session_state.history)}\")\n",
    "        with col2:\n",
    "            feedback = st.text_input(\"Optional feedback\", key=f\"fb_{len(st.session_state.history)}\")\n",
    "        if st.button(\"Submit rating\", key=f\"submit_{len(st.session_state.history)}\"):\n",
    "            st.session_state.ratings.append({\n",
    "                \"turn\": len(st.session_state.history),\n",
    "                \"prompt\": prompt,\n",
    "                \"reply\": reply,\n",
    "                \"score\": int(rating),\n",
    "                \"feedback\": feedback,\n",
    "            })\n",
    "            st.success(\"Thanks for your rating!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3532c08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.markdown(\"\\n\\n\")\n",
    "st.caption(\"Tip: adjust the threshold if responses feel too generic or too strict.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e789ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show simple usability stats\n",
    "if st.session_state.ratings:\n",
    "    scores = [r[\"score\"] for r in st.session_state.ratings]\n",
    "    avg = sum(scores) / len(scores)\n",
    "    st.markdown(f\"**Average user rating:** {avg:.2f} (n={len(scores)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc56aec2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
